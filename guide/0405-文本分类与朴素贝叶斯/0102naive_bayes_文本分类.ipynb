{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'x', 'y', 'x']\n",
      "0.3203 0.6797\n",
      "0.5857 0.4143\n",
      "0.3792 0.6208\n",
      "0.6470 0.3530\n",
      "Most Informative Features\n",
      "                       c = 0                   x : y      =      2.0 : 1.0\n",
      "                       c = 1                   y : x      =      1.5 : 1.0\n",
      "                       a = 1                   y : x      =      1.4 : 1.0\n",
      "                       b = 0                   x : y      =      1.2 : 1.0\n",
      "                       a = 0                   x : y      =      1.2 : 1.0\n",
      "                       b = 1                   y : x      =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "train = [\n",
    "    (dict(a=1,b=1,c=1), 'y'),\n",
    "    (dict(a=1,b=1,c=1), 'x'),\n",
    "    (dict(a=1,b=1,c=0), 'y'),\n",
    "    (dict(a=0,b=1,c=1), 'x'),\n",
    "    (dict(a=0,b=1,c=1), 'y'),\n",
    "    (dict(a=0,b=0,c=1), 'y'),\n",
    "    (dict(a=0,b=1,c=0), 'x'),\n",
    "    (dict(a=0,b=0,c=0), 'x'),\n",
    "    (dict(a=0,b=1,c=1), 'y'),\n",
    "]\n",
    "test=[\n",
    "    (dict(a=1,b=0,c=1)),\n",
    "    (dict(a=1,b=0,c=0)),\n",
    "    (dict(a=0,b=1,c=1)),\n",
    "    (dict(a=0,b=1,c=0)),\n",
    "]\n",
    "classifier = NaiveBayesClassifier.train(train)\n",
    "labels = classifier.classify_many(test)\n",
    "print(labels)\n",
    "\n",
    "probs = classifier.prob_classify_many(test)\n",
    "for pdist in probs:\n",
    "    print(\"%.4f %.4f\" % (pdist.prob('x'), pdist.prob('y')))\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_voc(data):\n",
    "    voc = {}\n",
    "    for (sentence,val) in data:\n",
    "        words = sentence.lower().split()\n",
    "        for w in words:\n",
    "            voc[w] = True\n",
    "    return voc\n",
    "\n",
    "\n",
    "def feature(data,v):\n",
    "    ftr = []\n",
    "    for (sentence,label) in data:\n",
    "        f = dict((w,0) for w in v.keys() )\n",
    "        words = sentence.lower().split()\n",
    "        for w in words:\n",
    "            f[w]=1\n",
    "        ftr.append((f,label))\n",
    "    return ftr\n",
    "\n",
    "def classify_eval(truth,pred):\n",
    "    idx = 0\n",
    "    (TP, FP, TN, FN) = (0, 0, 0, 0)\n",
    "    for truth_label in truth:\n",
    "        pred_label = pred[idx]\n",
    "        if( truth_label == 1 and pred_label == 1 ):\n",
    "            TP = TP + 1\n",
    "        elif( truth_label == 0 and pred_label == 0 ):\n",
    "            TN = TN +1\n",
    "        elif( truth_label == 1 and pred_label == 0 ):\n",
    "            FN = FN + 1\n",
    "        elif( truth_label == 0 and pred_label == 1 ):\n",
    "            FP = FP + 1\n",
    "        idx = idx + 1\n",
    "    P = 0 if TP == 0 else TP / (TP + FP)\n",
    "    R = 0 if TP == 0 else TP / (TP + FN)\n",
    "    F = 0 if (P == 0 or R == 0) else 2* P *R/(P + R)\n",
    "    Acc = 0 if (TP + TN == 0) else (TP + TN)/(TP + TN + FP + FN)\n",
    "    return (P,R,F,Acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, False]\n",
      "[False, True, True, False, True]\n",
      "Precision = 0.5000, Recall = 0.6667, F-score = 0.5714, Accuracy = 0.4000 \n",
      "0.7776 0.2224\n",
      "0.9459 0.0541\n",
      "0.9740 0.0260\n",
      "0.6602 0.3398\n",
      "0.1775 0.8225\n",
      "Most Informative Features\n",
      "                    game = 0               False : True   =      2.8 : 1.0\n",
      "                 comment = 0                True : False  =      1.8 : 1.0\n",
      "                     did = 0                True : False  =      1.8 : 1.0\n",
      "                      is = 0                True : False  =      1.8 : 1.0\n",
      "                     not = 0                True : False  =      1.8 : 1.0\n",
      "                    over = 0                True : False  =      1.8 : 1.0\n",
      "               president = 0                True : False  =      1.8 : 1.0\n",
      "                    show = 0                True : False  =      1.8 : 1.0\n",
      "                    ball = 0               False : True   =      1.7 : 1.0\n",
      "                   court = 0               False : True   =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_corpus = [(\"The team dominiated the game\", True),\n",
    "                (\"The game was intense\", True),\n",
    "                (\"The ball went off the court\", True),\n",
    "                (\"They had the ball for the whole game\", True),\n",
    "                (\"The President did not comment\", False),\n",
    "                (\"The show is over\", False),\n",
    "               ]\n",
    "v = build_voc(train_corpus)\n",
    "\n",
    "train_feature_label = feature(train_corpus, v)\n",
    "NBC = NaiveBayesClassifier.train(train_feature_label)\n",
    "\n",
    "test_corpus = [(\"I lost the keys\", False),\n",
    "                (\"The goalkeeper catched the ball\", True),\n",
    "                (\"The other team controlled the ball\", True),\n",
    "                (\"Sara has two kids\", False),\n",
    "                (\"This is a book\", True),\n",
    "               ]\n",
    "test_feature = []\n",
    "test_labels = []\n",
    "for (ftr, label) in feature(test_corpus, v):\n",
    "    test_feature.append(ftr)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "pred_labels = NBC.classify_many(test_feature)\n",
    "perf = classify_eval(test_labels, pred_labels)\n",
    "\n",
    "print(pred_labels)\n",
    "print(test_labels)\n",
    "\n",
    "print(\"Precision = %.4f, Recall = %.4f, F-score = %.4f, Accuracy = %.4f \" % \n",
    "      classify_eval(test_labels, pred_labels))\n",
    "\n",
    "probs = NBC.prob_classify_many(test_feature)\n",
    "for pdist in probs:\n",
    "    print(\"%.4f %.4f\" % (pdist.prob(True), pdist.prob(False)))\n",
    "\n",
    "\n",
    "NBC.show_most_informative_features(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, False]\n",
      "Precision = 0.5000, Recall = 0.6667, F-score = 0.5714, Accuracy = 0.4000 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "SVMC= SklearnClassifier(LinearSVC())\n",
    "SVMC.train(train_feature_label)\n",
    "pred_labels_SVM=[]\n",
    "for f in test_feature:\n",
    "    pred_labels_SVM.append(SVMC.classify(f))\n",
    "    \n",
    "print(pred_labels_SVM)\n",
    "print(\"Precision = %.4f, Recall = %.4f, F-score = %.4f, Accuracy = %.4f \" % \n",
    "      classify_eval(test_labels, pred_labels_SVM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
